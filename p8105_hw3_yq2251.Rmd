---
title: "p8105_hw3_yq2251"
author: "TritonD"
date: "10/12/2019"
output: github_document
---
```{r}
library(tidyverse)
library(ggridges)
library(patchwork)
library(knitr)
library(tidyr)
library(readxl)
```

## Problem 1
```{r}
library(p8105.datasets)
data("instacart")
```

**This instacart dataset contains 1,384,617 entries within 15 total columns.Some key variables include "asile" as a product category, "order_hour_of_day" which recognize people's ordering preferance in the time of a day.


## count how many aisles there are
```{r}
instacart %>%
  group_by(aisle) %>%
  summarize(aisle_n = n())
```

## find out which aisle is most popular
```{r}
instacart %>%
  group_by(aisle) %>%
  summarize(aisle_n = n())%>%
filter(min_rank(desc(aisle_n)) < 2)

```

**There are 134 aisles in total, with "fresh vegetables" as the aisle with most items ordered from (n=150609).



## Make a plot that shows the number of items ordered in each aisle with n>10000
```{r}
instacart %>%
  group_by(aisle) %>%
  summarize(aisle_n = n())%>%
filter(aisle_n > 10000)%>%
ggplot(aes(x=aisle, y=aisle_n)) +
  geom_bar(stat="identity") +
  theme(text = element_text(size=12),
         axis.text.x = element_text(angle=90, vjust=0.5)) +
  labs(
    title = "Ordering by aisle plot",
    x = "Aisle",
    y = "Number of items ordered in each aisle",
    caption = "Data from Instacart datasets"
  )
```

**In the bar chart title "Ordering by asile plot", x-axis is the 39 aisle names with more than 10000 items ordered, y-axis is the number of items ordered in each aisle with 50000 as a break. "Fresh vegetables" and "fresh fruits" are two outliers that were ordered a lot more times comparing to other products. Consumers prefer to order fruits and vegetables online.




## make a table for 3 most popular items in each of the 3 aisles 
```{r}
instacart %>%
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarize(product_count = n())%>%
  filter(min_rank(desc(product_count)) < 4)%>%
  knitr::kable(digits = 0)
```

**The three most popular items in "baking ingredients" aisle are Light Brown Sugar,Organic Vanilla Extract and Pure Baking Soda. The three most popular items in "dog food care" aisle are Organix Chicken & Brown Rice Recipe, Organix Grain Free Chicken & Vegetable Dog Food and Original Dry Dog. The three most popular items in "packaged vegetables fruits" aisle are Organic Baby Spinach, Organic Blueberries and Organic Raspberries. "Product_count" indicates number of products ordered for each product name."Product_count" listed how many orders had been placed. Packaged vegetables fruits are much more popular than other two aisles.




## Make a table showing the mean hour of the day 
```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name,order_dow) %>% 
  summarize(mean_time = mean(order_hour_of_day))%>%
   pivot_wider(
    names_from = order_dow,
    values_from = mean_time) %>% 
  rename(Sunday="0", Monday="1", Tuesday="2", Wednesday="3", Thursday="4", Friday="5", Saturday="6")%>%
  knitr::kable(digits = 0)
```

** This 2*7 table shows the mean hour of the day in the week when Pink Lady Apples and Coffee Ice Cream were ordered. According to the table, Coffee Ice Cream were usually purchased later in the day compared to Pink Lady Apples, which fits the general trend that vege/fruits are usually ordered earlier i the day comparing to ice cream/pizza.








## problem 2
```{r}
library(p8105.datasets)
data("brfss_smart2010")
```

## clean the dataset
```{r}
data("brfss_smart2010")
brfss_new=
  filter(brfss_smart2010,Topic=="Overall Health")%>%
  janitor::clean_names() %>%
  rename("state"=locationabbr)%>%
  mutate(
    response=as.factor(response),
    response = forcats::fct_relevel(response, c("Poor","Fair","Good", "Very good","Excellent")))
```


## In 2002, which states were observed at 7 or more locations? What about in 2010?
```{r}
brfss_new %>%
  filter(year == 2002)%>%
  group_by(state)%>%
 summarize(n_location=n_distinct(locationdesc), no.rm=FALSE)%>%
  filter(n_location>=7)%>%
  knitr::kable()
```

*In 2002, 6 states CT,FL,MA,NC,NJ,PA have 7 or more locations recorded.



```{r}
brfss_new %>%
  filter(year == 2010)%>%
  group_by(state)%>%
 summarize(n_location=n_distinct(locationdesc), no.rm=FALSE)%>%
  filter(n_location>=7)%>%
  knitr::kable()
```

*In 2010, 14 states CA,CO,FL,MA,MD,NC,NE,NJ,NY,OH,PA,SC,TX,WA have 7 or more locations recorded.



## Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value.
```{r}
brfss_excellent=
  filter(brfss_new, response == "Excellent")%>%
  group_by(year,state)%>%
  mutate(mean=mean(data_value, na.rm=FALSE, digits=2))%>%
  select(year,state,mean)%>%
  distinct()
```

*In this newly created dataset "brfss_excellent", there are 443 entries within 3 total columns, ranging from year 2002-2010.For 2010 FL/TX, 2006 PA, 2002 NJ the data is unknown.



## create the spaghetti plot of this average value over time within a state
```{r}
brfss_excellent %>%
  ggplot(aes(x=year,y=mean, color=state)) + 
    geom_line()+
  labs(
    title = "Average value over time for states plot",
    x = "year",
    y = "mean value",
    caption = "Data from the BRFSS package"
  ) +
  theme(legend.position = "left")
```

* For this spaghetti graph, x-axis is year, y-axis is the mean value of data_value with different colors represent different states.3 rows removed due to missing values.




## Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State

```{r}
brfss_new %>%
  filter(state == "NY", year %in% c(2006,2010))%>%
ggplot(aes(x = response, y = data_value, color=response)) + 
  geom_boxplot()+
   theme(text = element_text(size=12),
         axis.text.x = element_text(angle=90, vjust=0.5))+
  facet_grid(. ~ year)
```

*I choose to use a boxplot because it can show the distribution of data_value clearly. Different colors represent different response categories. The general trend of responses distribution is similar between year 2006 and 2010. In year 2010, there were more "very good" response" than "good" response comparing to 2006.





## problem 3

## clean the data with a weekday vs weekend variable
```{r}
accel=read_csv("data/accel_data.csv")%>%
 janitor::clean_names()%>%
  mutate(day = as.factor(day),
         day = forcats::fct_relevel(day, c("Sunday","Monday","Tuesday", "Wednesday","Thursday", "Friday", "Saturday"))) %>%
  mutate(daytype = case_when(
    day %in% c("Sunday","Saturday") ~ "weekend",
    day %in% c("Monday","Tuesday","Wednesday","Thursday","Friday") ~ "weekday"))%>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "time",
    names_prefix = "activity_",
    values_to = "activity"
  )
  mutate(accel, time = as.numeric(time))
```

*This dataset contains 50400 total entries with 6 total columns.Variables include week, day_id, day and daytype, time and activity. "daytype" indicates whether the day of the week is weekend(Saturday or Sunday) or weekday(Monday-Friday)."Time" is the sequence number of that specific activity records among the 35 days. "Activity" is the amount of activity recored for that single time.


## create daily total activity table
```{r}
accel%>%
  group_by(week,day, day_id) %>%
  summarize(Sum=sum(activity))%>%
  knitr::kable()
```

* In the newly created table, there are 35 rows with 4 columns. Variable"Sum" indicates the total amount of activity each day. Variable "week" indicates which week is that specific day.The days are arranged from Sunday to Saturday, which explains why the "day_id" was mixed up in a certain week. There is no apparent trend can be found from the table.


## create signle panel plot for 24-hour activity time courses for each day 

```{r}
accel_new = 
  accel %>%
  group_by(week,day, day_id) %>%
  summarize(Sum=sum(activity))

accel_new <- tibble::rowid_to_column(accel_new, "ID1")
```

```{r}
accel_new%>%
 ggplot(aes(x = day_id, y = Sum)) +
  geom_point(aes(color = day), alpha = .5)+
   geom_smooth(se = FALSE)

```

*According to the plot, majority of the person's daily activity summation is around 400000, with couple Saturdays when there is nearly none activities(sum of activity 1440). The maximum daily activity occurred on a Monday with nearly 700000. Different colors were used to represent differet days in the week. I order the data based on the real order of days happening in the week(from Sunday to Saturday as a week), the person's daily activity has a treand to increase at the beginning of the month, then decreased, and finally increased again.The graph seems to better visualize the data compared to the previously created table.




